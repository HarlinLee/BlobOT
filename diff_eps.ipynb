{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarlinLee/BlobOT/blob/main/diff_eps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cVZVi6u6KvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145b6138-c5f7-4bb6-91b2-50b4bb796a06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "230526\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/BlobOT-final\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, DRIVE_PATH)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import datetime\n",
        "date = datetime.datetime.today().strftime(\"%y%m%d\")\n",
        "print(date)\n",
        "\n",
        "import torch\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm8GlpK2KPtW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1accbccb-f413-4baf-935d-f53592ab44ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available(): \n",
        " dev = \"cuda:0\" \n",
        "else: \n",
        " dev = \"cpu\" \n",
        "device = torch.device(dev) \n",
        "print(device)\n",
        "\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZxJqx9vSJ-a"
      },
      "outputs": [],
      "source": [
        "from BlobOT import KE, NLE_pos, Model\n",
        "from BlobOT import draw_straight_lines, EarlyStopping, endpoint_cost, allpoint_cost\n",
        "\n",
        "def blobLoss(X, model):\n",
        "  ke = KE(X, model.z, model.params)\n",
        "  nle = NLE_pos(X, model.w, model.params)\n",
        "  return ke + nle, ke, nle\n",
        "\n",
        "\n",
        "def training_loop(model, optimizer, n=10000):\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True,\n",
        "                                                         patience=2, threshold=0,\n",
        "                                                         factor=0.2)\n",
        "  early_stopping = EarlyStopping(patience=5)\n",
        "\n",
        "  losses=[]\n",
        "  kes = []\n",
        "  nles = []\n",
        "  endpoint_costs = []\n",
        "  allpoint_costs = []\n",
        "\n",
        "  for i in range(n):\n",
        "    preds = model()\n",
        "    loss, ke, nle = blobLoss(preds, model)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step(loss)\n",
        "    early_stopping(loss)\n",
        "\n",
        "    losses.append(loss.cpu().detach())\n",
        "    kes.append(ke.cpu().detach())\n",
        "    nles.append(nle.cpu().detach())\n",
        "\n",
        "    X = preds.cpu().detach().numpy()\n",
        "    y = X[:,:,-1]\n",
        "\n",
        "    c1 = endpoint_cost(y, T(z))\n",
        "    endpoint_costs.append(c1)\n",
        "\n",
        "    c2 = allpoint_cost(X, T(z))\n",
        "    allpoint_costs.append(c2)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping at\", i, 'out of', n)\n",
        "      return (np.array(losses), np.array(kes), np.array(nles), \n",
        "              np.array(endpoint_costs), np.array(allpoint_costs))\n",
        "\n",
        "  return (np.array(losses), np.array(kes), np.array(nles), \n",
        "              np.array(endpoint_costs), np.array(allpoint_costs))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uy_jSefnDbI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670303a3-9591-4f67-b9c0-faa68268201c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'d': 1, 'dt': 0.2, 'L': 5, 'n': 300000, 'N': 20, 'delta': 0.05152052789556263, 'eps': 0.1, 'lr': 0.0001}\n",
            "endpoint cost: 0.025508059598301915 allpoint cost: 0.0174227294513793\n",
            "{'d': 1, 'dt': 0.2, 'L': 5, 'n': 300000, 'N': 20, 'delta': 0.05152052789556263, 'eps': 1, 'lr': 0.001}\n",
            "endpoint cost: 0.7610146782476647 allpoint cost: 0.521030925235018\n"
          ]
        }
      ],
      "source": [
        "rng = np.random.RandomState(23)\n",
        "\n",
        "d = 1\n",
        "dt = 0.2\n",
        "L = int(1/dt)\n",
        "\n",
        "gd_steps = 3*int(1e5) \n",
        "\n",
        "N = 20\n",
        "\n",
        "params = {'d': d, 'dt': dt, 'L': L, 'n': gd_steps, 'N': N}\n",
        "\n",
        "params['delta'] = N**(-0.99)\n",
        "\n",
        "epsilons = [0.1, 1] \n",
        "\n",
        "def T(x):\n",
        "  return 0.5*x+2\n",
        "\n",
        "z = np.sort(np.random.rand(N, d)) # uniform sampling from [0, 1]\n",
        "w = T(np.sort(np.random.rand(N, d))) # uniform sampling from [2, 2.5]\n",
        "\n",
        "z_tensor = torch.from_numpy(z).to(device)\n",
        "w_tensor = torch.from_numpy(w).to(device)\n",
        "\n",
        "y0 = np.ones((N, d))*(T(0) + T(1))/2 # initialize at 2.25\n",
        "X0 = draw_straight_lines(z, y0, params['L']+1)\n",
        "\n",
        "res = {'z': z, 'w': w, 'params': params, 'epsilons': epsilons}\n",
        "\n",
        "for j, eps in enumerate(epsilons):\n",
        "  params['eps'] = eps\n",
        "  params['lr'] = max(eps/1e3, 1e-5)\n",
        "\n",
        "  print(params)\n",
        "\n",
        "  # run gradient descent\n",
        "  m = Model(torch.from_numpy(X0), w_tensor, z_tensor, params)\n",
        "  opt = torch.optim.SGD(m.parameters(), lr=params['lr'])\n",
        "  losses, kes, nles, endpoint_costs, allpoint_costs = training_loop(m, opt, n=params['n'])\n",
        "  \n",
        "  X = m.X.data.cpu().detach().numpy()\n",
        "\n",
        "  print('endpoint cost:', endpoint_costs[-1],\n",
        "        'allpoint cost:', allpoint_costs[-1])\n",
        "  \n",
        "  # save results\n",
        "  res[str(eps)] = (X.copy(), losses, kes, nles, endpoint_costs, allpoint_costs)\n",
        "\n",
        "with open(os.path.join(DRIVE_PATH, f'diff_eps_{date}.pkl'), 'wb') as f:\n",
        "    pickle.dump(res, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting"
      ],
      "metadata": {
        "id": "3Y42gFxbi_Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/BlobOT-final\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import datetime\n",
        "date = datetime.datetime.today().strftime(\"%y%m%d\")\n",
        "print(date)\n",
        "\n",
        "import pickle"
      ],
      "metadata": {
        "id": "MM6UB3T-1lFF",
        "outputId": "12edb758-229d-4a52-96bf-1de1d051d8d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "230526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_one_run(res, params, ax, shifted=True):\n",
        "  (X, losses, kes, nles, endpoint_costs, allpoint_costs) = res\n",
        "  y = X[:,:,-1]\n",
        "\n",
        "  # plot particle trajectory\n",
        "  if X.shape[-1] <= params['L']:\n",
        "    X = np.concatenate((np.expand_dims(z, axis=-1), X), axis=-1)\n",
        "  \n",
        "  t = params['dt']*np.arange(params['L']+1)\n",
        "\n",
        "  for p in range(X.shape[0]):\n",
        "    traj = X[p].T\n",
        "    ax[0].plot(traj[:, 0], t,  color=[.5, .5, 1])\n",
        "  \n",
        "  ax[0].scatter(X[:, 0, 0], np.zeros_like(X[:, 0, 0]), marker='+', c='b', label='Source')\n",
        "  ax[0].scatter(w[:, 0], 1 + np.zeros_like(w[:, 0]), marker='x', c='r', label='Target')\n",
        "  ax[0].scatter(y[:, 0], 1 + np.zeros_like(y[:, 0]), marker='.', c='k', label='x(1)')\n",
        "  \n",
        "  # plot loss function values\n",
        "  steps = range(1, int(len(kes))+1)\n",
        "  \n",
        "  const_term1 = kes.min()-nles.min()\n",
        "\n",
        "  if shifted:\n",
        "    ax[1].plot(steps, losses-const_term1, linewidth=3, label=r'Total loss$^*$')\n",
        "    ax[1].plot(steps, kes-const_term1, linestyle='--', linewidth=3, label = r'Kinetic energy$^*$')\n",
        "  else:\n",
        "    ax[1].plot(steps, losses, linewidth=3, label=r'Total loss')\n",
        "    ax[1].plot(steps, kes, linestyle='--', linewidth=3, label = r'Kinetic energy')\n",
        "  \n",
        "  ax[1].plot(steps, nles, linestyle='-.', linewidth=3, label='Non-local energy')\n",
        "  ax[1].set_xscale('log')\n",
        "  ax[1].set_yscale('log')\n",
        "  \n",
        "  # plot error wrt OT map\n",
        "\n",
        "  ax[2].plot(steps, endpoint_costs, linewidth=3, label=r'At $t=1$')\n",
        "  ax[2].plot(steps, allpoint_costs, linestyle='--', linewidth=3, label = 'At all time points')\n",
        "  ax[2].set_xscale('log')\n",
        "  ax[2].set_yscale('log')\n",
        "  \n",
        "  # labeling things in the plot\n",
        "  kwarg = dict(fontsize=24)\n",
        "  leg_kwarg = dict(fontsize=16, markerscale=2)\n",
        "  tick_kwarg = dict(labelsize=16)\n",
        "  \n",
        "  ax[0].yaxis.set_tick_params(**tick_kwarg)\n",
        "  ax[1].yaxis.set_tick_params(**tick_kwarg)\n",
        "  ax[2].yaxis.set_tick_params(**tick_kwarg)\n",
        "    \n",
        "  ax[0].set_yticks([0, 1], ['$t$=0', '$t$=1'])\n",
        "  ax[2].set_yticks([0.1, 0.5, 1], [0.1, 0.5, 1])\n",
        "  \n",
        "  ax[0].set_ylabel(r'$\\epsilon=$'+str(params['eps']), **kwarg)\n",
        "\n",
        "  if j == 0:\n",
        "    ax[0].set_title(r'Particle trajectory', **kwarg)\n",
        "    ax[1].set_title('Objective function value', **kwarg)\n",
        "    ax[2].set_title('Error from OT map', **kwarg)\n",
        "  \n",
        "  if j == len(epsilons)-1:\n",
        "    ax[0].legend(**leg_kwarg)\n",
        "    ax[1].legend(loc='upper right', **leg_kwarg) # bbox_to_anchor=(0.4, 0.95)\n",
        "    ax[2].legend(**leg_kwarg)\n",
        "\n",
        "    ax[0].set_xlabel(r'1 dimensional $x(t)$', **kwarg)\n",
        "    ax[1].set_xlabel('Gradient descent steps', **kwarg)\n",
        "    ax[2].set_xlabel('Gradient descent steps', **kwarg)\n",
        "\n",
        "    ax[0].xaxis.set_tick_params(**tick_kwarg)\n",
        "    ax[1].xaxis.set_tick_params(**tick_kwarg)\n",
        "    ax[2].xaxis.set_tick_params(**tick_kwarg)\n",
        "  else:\n",
        "\n",
        "    ax[0].set_xticks([])\n",
        "    ax[1].set_xticks([])\n",
        "    ax[2].set_xticks([])\n",
        "\n",
        "    ax[0].set_xticks([], minor=True)\n",
        "    ax[1].set_xticks([], minor=True)\n",
        "    ax[2].set_xticks([], minor=True)\n"
      ],
      "metadata": {
        "id": "zRKvK63ulep-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLsDt22mLIhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb6bb31-5278-4387-a082-89e52ab13de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['z', 'w', 'params', 'epsilons', '0.1', '1'])\n",
            "6\n"
          ]
        }
      ],
      "source": [
        "with open(os.path.join(DRIVE_PATH, f'diff_eps_{date}.pkl'), 'rb') as f:\n",
        "    res = pickle.load(f)\n",
        "\n",
        "print(res.keys())\n",
        "print(len(res['1']))\n",
        "\n",
        "epsilons = res['epsilons']\n",
        "z, w, params = res['z'], res['w'], res['params']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for shifted in [True, False]:\n",
        "  fig, ax = plt.subplots(len(epsilons), 3, figsize=(5*3, 4*len(epsilons)))\n",
        "\n",
        "  for j, eps in enumerate(epsilons):\n",
        "    params['eps'] = eps\n",
        "    plot_one_run(res[str(eps)], params, ax[j,:], shifted=shifted)\n",
        "\n",
        "  # share x, y axis\n",
        "  if shifted:\n",
        "    for c in [1, 2]:\n",
        "      ylims = np.array([a.get_ylim() for a in ax[:, c]])\n",
        "      xlims = np.array([a.get_xlim() for a in ax[:, c]])\n",
        "\n",
        "      for cell in ax[:, c]:\n",
        "        cell.set_ylim((ylims.min(axis=0)[0], ylims.max(axis=0)[1]))\n",
        "        cell.set_xlim((xlims.min(axis=0)[0], xlims.max(axis=0)[1]))\n",
        "  else:\n",
        "    ylims = np.array([a.get_ylim() for a in ax[:, 2]])\n",
        "    xlims = np.array([a.get_xlim() for a in ax[:, 2]])\n",
        "\n",
        "    for cell in ax[:, 2]:\n",
        "      cell.set_ylim((ylims.min(axis=0)[0], ylims.max(axis=0)[1]))\n",
        "      cell.set_xlim((xlims.min(axis=0)[0], xlims.max(axis=0)[1]))\n",
        "    \n",
        "    ylims = np.array([a.get_ylim() for a in ax[:, 1]])\n",
        "    xlims = np.array([a.get_xlim() for a in ax[:, 1]])\n",
        "\n",
        "    for cell in ax[:, 1]:\n",
        "      cell.set_ylim((ylims.min(axis=0)[0], ylims.max(axis=0)[1]+100))\n",
        "      cell.set_xlim((xlims.min(axis=0)[0], xlims.max(axis=0)[1]+100))\n",
        "\n",
        "  plt.tight_layout(pad=0)\n",
        "  if shifted:\n",
        "    plt.savefig(os.path.join(DRIVE_PATH, f'diff_eps_{date}_shifted.pdf'), dpi=300)\n",
        "  else:\n",
        "    plt.savefig(os.path.join(DRIVE_PATH, f'diff_eps_{date}.pdf'), dpi=300)\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "qbLFlIlKGLYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cHawSE0z79E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+R9EKbOlJdcU2i5XnuDAt",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}